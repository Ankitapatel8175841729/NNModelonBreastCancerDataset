# -*- coding: utf-8 -*-
"""trainingPipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t5cjCQJy2Rc9STX1WPjVsNJ2AdKM6gfI
"""

import numpy as np
import pandas as pd
import torch
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder

df=pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')
df.head()

df.shape

df.drop(columns=['id', 'Unnamed: 32'], inplace= True)

df.head()

X_train,X_test, Y_train, Y_test=train_test_split(df.iloc[:,1:],df.iloc[:,0],test_size=0.2)

scaler=StandardScaler()
X_train=scaler.fit_transform(X_train)
X_test=scaler.transform(X_test)

X_train

Y_train

encoder=LabelEncoder()
Y_train=encoder.fit_transform(Y_train)
Y_test=encoder.transform(Y_test)

Y_train

X_train_tensor=torch.from_numpy(X_train)
X_test_tensor=torch.from_numpy(X_test)
Y_train_tensor=torch.from_numpy(Y_train)
Y_test_tensor=torch.from_numpy(Y_test)

X_train_tensor.shape

Y_train_tensor.shape

class MySimpleNN():

  def __init__(self, X):

    self.weights = torch.rand(X.shape[1], 1, dtype=torch.float64, requires_grad=True)
    self.bias = torch.zeros(1, dtype=torch.float64, requires_grad=True)

  def forward(self, X):
    z = torch.matmul(X, self.weights) + self.bias
    y_pred = torch.sigmoid(z)
    return y_pred

  def loss_function(self, y_pred, y):
    # Clamp predictions to avoid log(0)
    epsilon = 1e-7
    y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)

    # Calculate loss
    loss = -(Y_train_tensor * torch.log(y_pred) + (1 - Y_train_tensor) * torch.log(1 - y_pred)).mean()
    return loss

learning_rate=0.1
epochs=25

# create model
model = MySimpleNN(X_train_tensor)

# define loop
for epoch in range(epochs):

  # forward pass
  Y_pred = model.forward(X_train_tensor)

  # loss calculate
  loss = model.loss_function(Y_pred, Y_train_tensor)

  # backward pass
  loss.backward()

  # parameters update
  with torch.no_grad():
    model.weights -= learning_rate * model.weights.grad
    model.bias -= learning_rate * model.bias.grad

  # zero gradients
  model.weights.grad.zero_()
  model.bias.grad.zero_()

  # print loss in each epoch
  print(f'Epoch: {epoch + 1}, Loss: {loss.item()}')

model.bias

with torch.no_grad():
  Y_pred=model.forward(X_test_tensor)
  Y_pred=(Y_pred>0.9).float()
  accuracy=(Y_pred==Y_test_tensor).float().mean()
  print(f'Accuracy:{accuracy.item()}')

